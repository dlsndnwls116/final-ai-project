"""
AI ì˜ìƒ ìƒì„± ì„œë¹„ìŠ¤ - Stable Video Diffusion í†µí•©
"""
from __future__ import annotations

import os
import torch
from pathlib import Path
from typing import Optional, Callable, Tuple
from PIL import Image
import numpy as np
import imageio.v3 as iio

try:
    from diffusers import StableVideoDiffusionPipeline
    from diffusers.utils import load_image, export_to_video
    from huggingface_hub import hf_hub_download
    from huggingface_hub.errors import GatedRepoError
    SVD_AVAILABLE = True
except ImportError:
    SVD_AVAILABLE = False
    StableVideoDiffusionPipeline = None
    load_image = None
    export_to_video = None
    GatedRepoError = Exception

from utils.config import OPENAI_API_KEY
from utils.diagnostics import heartbeat
from .errors import AdGenError, ErrorCode

ROOT = Path(__file__).resolve().parents[1]

# Hugging Face í† í° í™•ì¸
HUGGINGFACE_HUB_TOKEN = os.getenv("HUGGINGFACE_HUB_TOKEN")
if not HUGGINGFACE_HUB_TOKEN:
    print("âš ï¸ HUGGINGFACE_HUB_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— ì¶”ê°€í•˜ì„¸ìš”.")

class SVDGenerator:
    """Stable Video Diffusion ì˜ìƒ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.pipeline = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model_id = "stabilityai/stable-video-diffusion-img2vid-xt-1-1"
        
    def _ensure_loaded(self) -> None:
        """íŒŒì´í”„ë¼ì¸ ë¡œë“œ (í•„ìš”ì‹œ)"""
        if self.pipeline is not None:
            return
            
        if not SVD_AVAILABLE:
            raise AdGenError(
                ErrorCode.EXTERNAL_API_FAIL,
                "SVD íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
                hint="pip install diffusers transformers accelerate"
            )
        
        heartbeat("svd_loading")
        print(f"ğŸ¤– SVD ëª¨ë¸ ë¡œë”© ì¤‘... (ë””ë°”ì´ìŠ¤: {self.device})")
        
        try:
            # ëª¨ë¸ ë¡œë“œ
            self.pipeline = StableVideoDiffusionPipeline.from_pretrained(
                self.model_id,
                torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                variant="fp16" if self.device == "cuda" else None,
                use_auth_token=HUGGINGFACE_HUB_TOKEN
            )
            
            # GPU ìµœì í™”
            if self.device == "cuda":
                self.pipeline = self.pipeline.to(self.device)
                self.pipeline.enable_model_cpu_offload()  # ë©”ëª¨ë¦¬ ì ˆì•½
                
            print("âœ… SVD ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
        except GatedRepoError as e:
            raise AdGenError(
                ErrorCode.EXTERNAL_API_FAIL,
                "SVD ê²Œì´íŠ¸ ì €ì¥ì†Œ ì ‘ê·¼ ê±°ë¶€ (401 Unauthorized)",
                hint="Hugging Faceì—ì„œ ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œì„ ì‹ ì²­í•˜ê³  í† í°ì„ ì„¤ì •í•˜ì„¸ìš”",
                detail=f"GatedRepoError: {str(e)}"
            )
        except torch.cuda.OutOfMemoryError as e:
            raise AdGenError(
                ErrorCode.RENDER_FAILED,
                "GPU ë©”ëª¨ë¦¬ ë¶€ì¡± (OOM)",
                hint="í”„ë ˆì„ ìˆ˜ë¥¼ ì¤„ì´ê±°ë‚˜ ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•˜ì„¸ìš”",
                detail=f"CUDA OOM: {str(e)}"
            )
        except Exception as e:
            raise AdGenError(
                ErrorCode.EXTERNAL_API_FAIL,
                f"SVD ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}",
                hint="Hugging Face í† í°ê³¼ GPU ë©”ëª¨ë¦¬ë¥¼ í™•ì¸í•˜ì„¸ìš”",
                detail=str(e)
            )
    
    def generate_video(
        self, 
        image_path: str | Path,
        num_frames: int = 25,
        motion_bucket_id: int = 127,
        noise_aug_strength: float = 0.02,
        progress_callback: Optional[Callable[[float, str], None]] = None
    ) -> Tuple[str, dict]:
        """
        ì´ë¯¸ì§€ì—ì„œ ì˜ìƒ ìƒì„±
        
        Args:
            image_path: ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ
            num_frames: ìƒì„±í•  í”„ë ˆì„ ìˆ˜ (25 = 1ì´ˆ@25fps)
            motion_bucket_id: ì›€ì§ì„ ê°•ë„ (1-255)
            noise_aug_strength: ë…¸ì´ì¦ˆ ê°•ë„
            progress_callback: ì§„í–‰ë¥  ì½œë°± (pct, message)
            
        Returns:
            (output_video_path, metadata)
        """
        self._ensure_loaded()
        
        image_path = Path(image_path)
        if not image_path.exists():
            raise AdGenError(
                ErrorCode.MISSING_PRODUCT,
                f"ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}"
            )
        
        # ì¶œë ¥ ê²½ë¡œ ì„¤ì •
        output_dir = ROOT / "outputs" / "ai_videos"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = int(torch.cuda.Event(enable_timing=True).elapsed_time(torch.cuda.Event(enable_timing=True)) * 1000)
        output_path = output_dir / f"svd_generated_{timestamp}.mp4"
        
        try:
            heartbeat("svd_preprocess")
            if progress_callback:
                progress_callback(10, "ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘...")
            
            # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
            image = load_image(str(image_path))
            image = image.resize((1024, 576))  # SVD ê¶Œì¥ í•´ìƒë„
            
            heartbeat("svd_generation")
            if progress_callback:
                progress_callback(20, "AI ì˜ìƒ ìƒì„± ì¤‘...")
            
            # ì˜ìƒ ìƒì„± (SVD íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ)
            gen = torch.Generator(device=self.device).manual_seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼
            result = self.pipeline(
                image=image,
                num_frames=num_frames,
                decode_chunk_size=8,          # ë©”ëª¨ë¦¬ ì ˆì•½
                motion_bucket_id=motion_bucket_id,
                noise_aug_strength=noise_aug_strength,
                fps=25,                       # ê³ ì • fps
                generator=gen,
            )
            # diffusers 0.30.0 ê¸°ì¤€ ë°˜í™˜ì€ .frames[0]ì— í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸
            frames = result.frames[0] if hasattr(result, "frames") else result[0]
            
            heartbeat("svd_export")
            if progress_callback:
                progress_callback(90, "ì˜ìƒ ë‚´ë³´ë‚´ê¸° ì¤‘...")
            
            # ë¹„ë””ì˜¤ë¡œ ë‚´ë³´ë‚´ê¸° (PIL.Image ë¦¬ìŠ¤íŠ¸ë¥¼ numpy arrayë¡œ ë³€í™˜)
            arr = [np.array(img) for img in frames]
            iio.mimwrite(str(output_path), arr, fps=25, codec="h264", quality=8)
            
            # ë©”íƒ€ë°ì´í„°
            metadata = {
                "model": self.model_id,
                "input_image": str(image_path),
                "output_video": str(output_path),
                "num_frames": num_frames,
                "motion_bucket_id": motion_bucket_id,
                "noise_aug_strength": noise_aug_strength,
                "duration": num_frames / 25.0,  # ì´ˆ
                "resolution": "1024x576",
                "fps": 25
            }
            
            if progress_callback:
                progress_callback(100, f"ì™„ë£Œ! {output_path}")
            
            return str(output_path), metadata
            
        except Exception as e:
            raise AdGenError(
                ErrorCode.RENDER_FAILED,
                f"SVD ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {str(e)}",
                detail=f"ëª¨ë¸: {self.model_id}, ì…ë ¥: {image_path}",
                hint="GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. num_framesë‚˜ inference_stepsë¥¼ ì¤„ì—¬ë³´ì„¸ìš”."
            )
    
    def cleanup(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        if self.pipeline:
            del self.pipeline
            self.pipeline = None
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_svd_generator: Optional[SVDGenerator] = None

def get_svd_generator() -> SVDGenerator:
    """SVD ìƒì„±ê¸° ì‹±ê¸€í†¤"""
    global _svd_generator
    if _svd_generator is None:
        _svd_generator = SVDGenerator()
    return _svd_generator

def generate_ai_video(
    image_path: str | Path,
    duration_seconds: float = 1.0,
    motion_level: str = "medium",
    quality: str = "standard",
    progress_callback: Optional[Callable[[float, str], None]] = None
) -> Tuple[str, dict]:
    """
    í¸ì˜ í•¨ìˆ˜: AI ì˜ìƒ ìƒì„±
    
    Args:
        image_path: ì…ë ¥ ì´ë¯¸ì§€
        duration_seconds: ì˜ìƒ ê¸¸ì´ (ì´ˆ)
        motion_level: "low", "medium", "high"
        quality: "fast", "standard", "high"
        progress_callback: ì§„í–‰ë¥  ì½œë°±
        
    Returns:
        (output_video_path, metadata)
    """
    # ì„¤ì • ë§¤í•‘
    motion_configs = {
        "low": {"motion_bucket_id": 65, "noise_aug_strength": 0.01},
        "medium": {"motion_bucket_id": 127, "noise_aug_strength": 0.02},
        "high": {"motion_bucket_id": 200, "noise_aug_strength": 0.05}
    }
    
    quality_configs = {
        "fast": {"num_frames": 25},
        "standard": {"num_frames": 50},
        "high": {"num_frames": 75}
    }
    
    # í”„ë ˆì„ ìˆ˜ ê³„ì‚° (duration_seconds ê¸°ë°˜)
    base_frames = int(duration_seconds * 25)  # 25fps ê¸°ì¤€
    base_frames = max(25, min(base_frames, 100))  # 1-4ì´ˆ ë²”ìœ„
    
    config = {
        **motion_configs.get(motion_level, motion_configs["medium"]),
        **quality_configs.get(quality, quality_configs["standard"]),
        "num_frames": base_frames
    }
    
    generator = get_svd_generator()
    return generator.generate_video(
        image_path=image_path,
        progress_callback=progress_callback,
        **config
    )

def is_svd_available() -> bool:
    """SVD ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
    if not SVD_AVAILABLE:
        return False
    if not HUGGINGFACE_HUB_TOKEN:
        return False
    try:
        # ì‹¤ì œ ëª¨ë¸ ì ‘ê·¼ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        hf_hub_download(
            "stabilityai/stable-video-diffusion-img2vid-xt-1-1", 
            "model_index.json",
            use_auth_token=HUGGINGFACE_HUB_TOKEN
        )
        return True
    except Exception:
        return False

__all__ = [
    "generate_ai_video", 
    "get_svd_generator", 
    "is_svd_available",
    "SVDGenerator"
]
