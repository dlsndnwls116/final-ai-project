"""
S4. íƒ€ì„ë¼ì¸ í•©ì„± & ë Œë” ì—”ì§„
recipe.json + ì‚¬ìš©ì ìì‚°ì„ ë§¤í•‘í•´ì„œ ê°™ì€ ê¸°ë²•(ì „í™˜/ì¤Œ/íŒ”ë ˆíŠ¸/íƒ€ì´í¬/ì˜¤ë²„ë ˆì´)ìœ¼ë¡œ 9:16 mp4 ìƒì„±
"""

import json
import os
from collections.abc import Callable
from pathlib import Path
from typing import Any

import numpy as np
from moviepy.editor import *
from moviepy.video.fx import resize
from PIL import Image, ImageDraw, ImageFont


def pil_rgba_to_clip(im_rgba: Image.Image, duration: float) -> VideoClip:
    """PIL RGBA ì´ë¯¸ì§€ë¥¼ moviepy VideoClipìœ¼ë¡œ ë³€í™˜ (RGB+mask ë¶„ë¦¬)"""
    # RGBAë¡œ ë³€í™˜
    rgba_array = np.array(im_rgba.convert("RGBA"))

    # RGBì™€ Alpha ë¶„ë¦¬
    rgb_array = rgba_array[:, :, :3]
    alpha_array = (rgba_array[:, :, 3] / 255.0).astype("float32")

    # RGB í´ë¦½ ìƒì„±
    rgb_clip = ImageClip(rgb_array).set_duration(duration)

    # Alpha ë§ˆìŠ¤í¬ ìƒì„±
    alpha_mask = ImageClip(alpha_array, ismask=True).set_duration(duration)

    # ë§ˆìŠ¤í¬ ì ìš©
    return rgb_clip.set_mask(alpha_mask)


# 9:16 ëª¨ë°”ì¼ ë¹„ë””ì˜¤ ì„¤ì •
MOBILE_WIDTH = 1080
MOBILE_HEIGHT = 1920
MOBILE_FPS = 30


def fit_cover(clip: VideoClip, size: tuple) -> VideoClip:
    """fit:cover íš¨ê³¼ ì ìš© (í™”ë©´ì„ ì™„ì „íˆ ì±„ìš°ë„ë¡ í¬ë¡­)"""
    W, H = size
    w, h = clip.size

    # í™”ë©´ì„ ì™„ì „íˆ ì±„ìš°ëŠ” ìµœì†Œ ìŠ¤ì¼€ì¼ ê³„ì‚°
    scale = max(W / w, H / h)

    # ë¦¬ì‚¬ì´ì¦ˆ í›„ ì¤‘ì•™ í¬ë¡­
    return clip.resize(scale).crop(
        x_center=(w * scale) / 2, y_center=(h * scale) / 2, width=W, height=H
    )


def shot_bounds(s):
    """ìƒ·ì˜ ì‹œê°„ ë²”ìœ„ë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸° (t ë˜ëŠ” in/out í˜¸í™˜)"""
    if "t" in s and isinstance(s["t"], (list, tuple)) and len(s["t"]) == 2:
        a, b = s["t"]
        return float(a), float(b)
    return float(s.get("in", 0)), float(s.get("out", 0))


def shot_duration(s):
    """ìƒ·ì˜ ì§€ì†ì‹œê°„ì„ ì•ˆì „í•˜ê²Œ ê³„ì‚°"""
    a, b = shot_bounds(s)
    return b - a


def text_clip_pil(
    text,
    size=(1080, 1920),
    fontsize=64,
    color="white",
    font_path=None,
    bg=(0, 0, 0, 0),
    duration=2,
    pos="center",
):
    """PILì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ í´ë¦½ ìƒì„± (ImageMagick ì˜ì¡´ì„± ì œê±°)"""
    img = Image.new("RGBA", size, bg)
    draw = ImageDraw.Draw(img)
    try:
        font = ImageFont.truetype(font_path or "arial.ttf", fontsize)
    except:
        font = ImageFont.load_default()
    bbox = draw.textbbox((0, 0), text, font=font)
    w, h = bbox[2] - bbox[0], bbox[3] - bbox[1]

    if pos == "center":
        x, y = (size[0] - w) // 2, (size[1] - h) // 2
    elif pos == "top":
        x, y = (size[0] - w) // 2, 50
    elif pos == "bottom":
        x, y = (size[0] - w) // 2, size[1] - h - 50
    else:
        x, y = pos

    draw.text((x, y), text, font=font, fill=color)
    # ê¸°ì¡´ ë°©ì‹ ëŒ€ì‹  ìƒˆë¡œìš´ RGBA ë³€í™˜ ìœ í‹¸ ì‚¬ìš©
    return pil_rgba_to_clip(img, duration)


def load_assets_from_directory(assets_dir: str) -> dict[str, str]:
    """ìì‚° ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ë“¤ì„ ë¡œë“œ"""
    assets = {}
    assets_path = Path(assets_dir)

    if not assets_path.exists():
        return assets

    # ì´ë¯¸ì§€ íŒŒì¼ë“¤
    for img_file in assets_path.glob("images/*"):
        if img_file.suffix.lower() in [".png", ".jpg", ".jpeg"]:
            assets[img_file.stem] = str(img_file)

    # ë¹„ë””ì˜¤ íŒŒì¼ë“¤
    for vid_file in assets_path.glob("videos/*"):
        if vid_file.suffix.lower() in [".mp4", ".mov", ".avi"]:
            assets[vid_file.stem] = str(vid_file)

    # í…ìŠ¤íŠ¸ íŒŒì¼ë“¤
    for txt_file in assets_path.glob("texts/*"):
        if txt_file.suffix.lower() in [".txt"]:
            with open(txt_file, encoding="utf-8") as f:
                assets[txt_file.stem] = f.read().strip()

    return assets


def create_text_clip(
    text_data: dict[str, Any], width: int = MOBILE_WIDTH, height: int = MOBILE_HEIGHT
) -> TextClip:
    """í…ìŠ¤íŠ¸ í´ë¦½ ìƒì„± (ë³¼ë“œ+ì™¸ê³½ì„ +ìŠ¬ë¼ì´ë“œ)"""

    content = text_data.get("content", "")
    start_time = text_data.get("t", 0)
    duration = text_data.get("t_end", 0) - start_time
    position = text_data.get("position", "center")

    # í°íŠ¸ ì„¤ì •
    font_size = text_data.get("font_size", 72)
    font_color = text_data.get("color", "white")
    stroke_color = text_data.get("stroke_color", "black")
    stroke_width = text_data.get("stroke_width", 3)

    # í…ìŠ¤íŠ¸ í´ë¦½ ìƒì„±
    text_clip = (
        TextClip(
            content,
            font="Arial-Bold",  # Pretendard-Bold ëŒ€ì‹  Arial-Bold ì‚¬ìš©
            fontsize=font_size,
            color=font_color,
            stroke_color=stroke_color,
            stroke_width=stroke_width,
            method="caption",
            size=(width * 0.9, None),  # í™”ë©´ ë„ˆë¹„ì˜ 90% ì‚¬ìš©
        )
        .set_start(start_time)
        .set_duration(duration)
    )

    # ìœ„ì¹˜ ì„¤ì •
    if position == "center":
        text_clip = text_clip.set_position(("center", "center"))
    elif position == "top":
        text_clip = text_clip.set_position(("center", height * 0.1))
    elif position == "bottom":
        text_clip = text_clip.set_position(("center", height * 0.8))

    return text_clip


def create_placeholder_clip(duration: float, color: str = "#141414", text: str = "") -> VideoClip:
    """í”Œë ˆì´ìŠ¤í™€ë” í´ë¦½ ìƒì„± (ë‹¨ìƒ‰+í…ìŠ¤íŠ¸, PIL ê¸°ë°˜)"""

    if text:
        # PIL ê¸°ë°˜ìœ¼ë¡œ í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ í´ë¦½ ìƒì„±
        try:
            # PIL ê¸°ë°˜ìœ¼ë¡œ RGBA ì´ë¯¸ì§€ ìƒì„± í›„ pil_rgba_to_clip ì‚¬ìš©
            img = Image.new("RGBA", (MOBILE_WIDTH, MOBILE_HEIGHT), color)
            draw = ImageDraw.Draw(img)
            try:
                font = ImageFont.truetype("arial.ttf", 48)
            except:
                font = ImageFont.load_default()

            bbox = draw.textbbox((0, 0), text, font=font)
            w, h = bbox[2] - bbox[0], bbox[3] - bbox[1]
            x, y = (MOBILE_WIDTH - w) // 2, (MOBILE_HEIGHT - h) // 2
            draw.text((x, y), text, font=font, fill="white")

            return pil_rgba_to_clip(img, duration)
        except Exception as e:
            print(f"PIL í…ìŠ¤íŠ¸ ì‹¤íŒ¨, ë‹¨ìƒ‰ìœ¼ë¡œ ëŒ€ì²´: {e}")
            # PIL ì‹¤íŒ¨ ì‹œ ë‹¨ìƒ‰ í´ë¦½ë§Œ ë°˜í™˜
            pass

    # í…ìŠ¤íŠ¸ê°€ ì—†ê±°ë‚˜ PIL ì‹¤íŒ¨ ì‹œ ë‹¨ìƒ‰ í´ë¦½
    return ColorClip(size=(MOBILE_WIDTH, MOBILE_HEIGHT), color=color, duration=duration)


def apply_motion_effects(clip: VideoClip, motion: dict[str, Any]) -> VideoClip:
    """ëª¨ì…˜ íš¨ê³¼ ì ìš© (ì¤Œ/íŒ¬/í‹¸íŠ¸)"""

    motion_type = motion.get("type", "static")
    intensity = motion.get("intensity", 0.0)

    if motion_type == "zoom-in-slow":
        # ì²œì²œíˆ ì¤Œì¸
        def zoom_func(t):
            return 1 + 0.05 * t

        clip = clip.fx(resize, zoom_func)

    elif motion_type == "zoom-out-slow":
        # ì²œì²œíˆ ì¤Œì•„ì›ƒ
        def zoom_func(t):
            return 1.2 - 0.05 * t

        clip = clip.fx(resize, zoom_func)

    elif motion_type == "pan":
        # íŒ¬ íš¨ê³¼
        pan_intensity = intensity * 0.1

        def pan_func(t):
            return (pan_intensity * t, 0)

        clip = clip.set_position(pan_func)

    return clip


def _clip_from_layer(
    layer: dict[str, Any],
    assets: dict[str, str],
    W: int = 1080,
    H: int = 1920,
    default_dur: float = 2.0,
    diag: dict | None = None,
) -> VideoClip:
    """ë ˆì´ì–´ì—ì„œ í´ë¦½ ìƒì„± (ì§„ë‹¨ ì •ë³´ ìˆ˜ì§‘)"""
    from moviepy.editor import ColorClip, CompositeVideoClip

    kind = layer.get("type")
    ref = layer.get("ref")
    dur = float(layer.get("dur", default_dur))
    dur = max(0.2, dur)  # ìµœì†Œ 0.2ì´ˆ

    if kind in ("video", "image"):
        path = assets.get(ref)
        if not path or not Path(path).exists():
            if diag is not None:
                diag["missing"].add(ref or "<empty-ref>")
                diag["reasons"].append(f"missing asset for ref={ref}")
            # í”Œë ˆì´ìŠ¤í™€ë” ìƒì„±í•˜ì—¬ ì§„í–‰ (PIL ê¸°ë°˜)
            bg = ColorClip((W, H), color=(245, 245, 245), duration=dur)
            txt = text_clip_pil(
                f"Missing: {ref}", size=(W, H), fontsize=50, color="red", duration=dur
            )
            return CompositeVideoClip([bg, txt])

        # ì‹¤ì œ íŒŒì¼ì„ ì—¬ëŠ” ë¡œì§
        try:
            if path.lower().endswith((".mp4", ".mov", ".avi")):
                clip = VideoFileClip(path).subclip(0, min(dur, 10))
                clip = fit_cover(clip, (W, H))  # fit:cover ê°•ì œ ì ìš©
            else:
                clip = ImageClip(path).set_duration(dur)
                clip = fit_cover(clip, (W, H))  # fit:cover ê°•ì œ ì ìš©
            return clip
        except Exception as e:
            if diag is not None:
                diag["reasons"].append(f"failed to load {ref}: {str(e)}")
            # ì‹¤íŒ¨ ì‹œ í”Œë ˆì´ìŠ¤í™€ë” (PIL ê¸°ë°˜)
            bg = ColorClip((W, H), color=(245, 245, 245), duration=dur)
            txt = text_clip_pil(
                f"Error: {ref}", size=(W, H), fontsize=50, color="red", duration=dur
            )
            return CompositeVideoClip([bg, txt])

    elif kind == "text":
        txt = layer.get("text", "").strip()
        if not txt:
            if diag is not None:
                diag["reasons"].append("empty text layer")
            return None

        # PIL ê¸°ë°˜ í…ìŠ¤íŠ¸ í´ë¦½ ìƒì„± (ImageMagick ì˜ì¡´ì„± ì™„ì „ ì œê±°)
        try:
            # í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ ì •ë³´ ì¶”ì¶œ
            style = layer.get("style", {})
            fontsize = style.get("fontsize", 64)
            color = style.get("color", "white")
            position = style.get("position", "center")

            text_clip = text_clip_pil(
                txt, size=(W, H), fontsize=fontsize, color=color, duration=dur, pos=position
            )
            return text_clip
        except Exception as e:
            if diag is not None:
                diag["reasons"].append(f"text clip error: {str(e)}")
            # í…ìŠ¤íŠ¸ ì‹¤íŒ¨ ì‹œì—ë„ ê¸°ë³¸ í…ìŠ¤íŠ¸ë¡œ ëŒ€ì²´
            try:
                fallback_clip = text_clip_pil(
                    f"TEXT ERROR: {txt[:20]}...",
                    size=(W, H),
                    fontsize=40,
                    color="red",
                    duration=dur,
                )
                return fallback_clip
            except:
                return None

    else:
        if diag is not None:
            diag["reasons"].append(f"unknown layer type: {kind}")
        return None


def build_shot_clip(
    shot: dict[str, Any],
    assets: dict[str, str],
    progress_cb: Callable | None = None,
    safe_mode: bool = False,
) -> VideoClip:
    """ìƒ· í´ë¦½ ë¹Œë“œ (ë””ë²„ê·¸ ì›Œí„°ë§ˆí¬ + ì•ˆì „í•œ í•©ì„± ìˆœì„œ)"""

    # ìƒˆë¡œìš´ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš© (t ë˜ëŠ” in/out í˜¸í™˜)
    start_time, end_time = shot_bounds(shot)
    duration = shot_duration(shot)

    # ìµœì†Œ ê¸¸ì´ ë³´ì¥
    if duration <= 0:
        duration = 2.0

    shot_idx = shot.get("idx", 0)
    size = (MOBILE_WIDTH, MOBILE_HEIGHT)

    # ë ˆì´ì–´ ì²˜ë¦¬
    layers = shot.get("layers", [])
    if not layers:
        # ê¸°ì¡´ í˜•ì‹ ì§€ì› - ë‹¨ìˆœí•œ ìì‚° ë¡œë“œ
        video_asset = None
        for asset_key in [
            "product_shot",
            "store_exterior",
            "brand_logo",
            "product",
            "store",
            "broll1",
            "broll2",
        ]:
            if asset_key in assets:
                video_asset = assets[asset_key]
                break

        if video_asset and os.path.exists(video_asset):
            try:
                if video_asset.lower().endswith((".mp4", ".mov", ".avi")):
                    base = VideoFileClip(video_asset).subclip(0, min(duration, 10))
                else:
                    base = ImageClip(video_asset).set_duration(duration)
                base = fit_cover(base, size).set_opacity(1)  # fit:cover ê°•ì œ ì ìš©
            except Exception as e:
                print(f"ìì‚° ë¡œë“œ ì‹¤íŒ¨: {e}")
                base = create_placeholder_clip(
                    duration, "#1a1a1a", f"ìì‚° ë¡œë“œ ì‹¤íŒ¨: {video_asset}"
                )
        else:
            base = create_placeholder_clip(duration, "#141414", f"ìƒ· {shot_idx + 1}")

        # ê°•í™”ëœ ë””ë²„ê·¸ ì›Œí„°ë§ˆí¬ ì¶”ê°€
        debug_text = f"SHOT {shot_idx}\n{start_time:.1f}s-{end_time:.1f}s\n{duration:.1f}s"
        debug_overlay = text_clip_pil(
            debug_text,
            size=size,
            fontsize=60,
            color="yellow",
            bg=(0, 0, 0, 128),  # ë°˜íˆ¬ëª… ê²€ì€ ë°°ê²½
            duration=duration,
            pos=(40, 40),
        )

        # ì¶”ê°€ ë””ë²„ê·¸ ì •ë³´ (ìš°ì¸¡ í•˜ë‹¨)
        info_text = f"Legacy Mode\nAssets: {len(assets)}"
        info_overlay = text_clip_pil(
            info_text,
            size=size,
            fontsize=40,
            color="cyan",
            bg=(0, 0, 0, 128),
            duration=duration,
            pos=(size[0] - 200, size[1] - 100),
        )

        return CompositeVideoClip([base, debug_overlay, info_overlay], size=size).set_duration(
            duration
        )

    # ìƒˆë¡œìš´ ë ˆì‹œí”¼ í˜•ì‹ ì²˜ë¦¬
    diagnostics = {"missing": set(), "reasons": []}
    base_clip = None
    overlays = []

    # 1. ë² ì´ìŠ¤ ë¹„ë””ì˜¤/ì´ë¯¸ì§€ ë ˆì´ì–´ ì°¾ê¸° (ë°˜ë“œì‹œ ì²« ë²ˆì§¸)
    for layer in layers:
        if layer.get("type") in ("video", "image"):
            layer_clip = _clip_from_layer(
                layer, assets, MOBILE_WIDTH, MOBILE_HEIGHT, duration, diagnostics
            )
            if layer_clip is not None:
                base_clip = layer_clip.set_opacity(1)  # ì•ŒíŒŒ ì²˜ë¦¬ ì•ˆì „ì¥ì¹˜
                break

    # ë² ì´ìŠ¤ í´ë¦½ì´ ì—†ìœ¼ë©´ í”Œë ˆì´ìŠ¤í™€ë” ìƒì„±
    if base_clip is None:
        base_clip = create_placeholder_clip(duration, "#141414", f"ìƒ· {shot_idx + 1}")

    # 2. ì˜¤ë²„ë ˆì´ ë ˆì´ì–´ë“¤ ì²˜ë¦¬ (Safe Modeì—ì„œëŠ” ê±´ë„ˆë›°ê¸°)
    if not safe_mode:
        for layer in layers:
            layer_type = layer.get("type")
            if layer_type == "text":
                try:
                    text_clip = text_clip_pil(
                        layer.get("text", ""),
                        size=size,
                        fontsize=64,
                        color="white",
                        duration=duration,
                        pos="center",
                    )
                    overlays.append(text_clip)
                except Exception as e:
                    print(f"shot#{shot_idx} text layer skipped: {e}")

    # 3. ê°•í™”ëœ ë””ë²„ê·¸ ì›Œí„°ë§ˆí¬ ì¶”ê°€ (ë¬´ì¡°ê±´)
    mode_indicator = "SAFE MODE" if safe_mode else "NORMAL"
    debug_text = (
        f"SHOT {shot_idx} [{mode_indicator}]\n{start_time:.1f}s-{end_time:.1f}s\n{duration:.1f}s"
    )
    debug_overlay = text_clip_pil(
        debug_text,
        size=size,
        fontsize=60,
        color="yellow" if not safe_mode else "green",
        bg=(0, 0, 0, 128),  # ë°˜íˆ¬ëª… ê²€ì€ ë°°ê²½
        duration=duration,
        pos=(40, 40),
    )
    overlays.append(debug_overlay)

    # 4. ì¶”ê°€ ë””ë²„ê·¸ ì •ë³´ (ìš°ì¸¡ í•˜ë‹¨)
    overlay_count = (
        len([l for l in layers if l.get("type") in ("text", "solid", "vignette", "grain", "glow")])
        if not safe_mode
        else 0
    )
    info_text = f"Layers: {len(layers)}\nOverlays: {overlay_count}\nAssets: {len(assets)}"
    info_overlay = text_clip_pil(
        info_text,
        size=size,
        fontsize=40,
        color="cyan" if not safe_mode else "lime",
        bg=(0, 0, 0, 128),
        duration=duration,
        pos=(size[0] - 200, size[1] - 100),
    )
    overlays.append(info_overlay)

    # 4. ì•ˆì „í•œ í•©ì„± ìˆœì„œ: [ë² ì´ìŠ¤, *ì˜¤ë²„ë ˆì´ë“¤] - baseê°€ ë°˜ë“œì‹œ ì²« ë²ˆì§¸
    all_layers = [base_clip] + overlays
    if len(all_layers) == 1:
        return all_layers[0]
    else:
        # baseê°€ ì²« ë²ˆì§¸ì„ì„ ë³´ì¥í•˜ê³  size ê°•ì œ ì„¤ì •
        return CompositeVideoClip(all_layers, size=size).set_duration(duration)


def create_transition_effect(
    clip1: VideoClip, clip2: VideoClip, transition_type: str = "fade"
) -> VideoClip:
    """ì „í™˜ íš¨ê³¼ ìƒì„±"""

    if transition_type == "fade":
        # í˜ì´ë“œ ì „í™˜
        clip1 = clip1.fadeout(0.5)
        clip2 = clip2.fadein(0.5)
    elif transition_type == "slide":
        # ìŠ¬ë¼ì´ë“œ ì „í™˜
        clip2 = clip2.set_position(lambda t: (MOBILE_WIDTH * (1 - t), 0))

    return concatenate_videoclips([clip1, clip2], method="compose")


def render_video(
    recipe_path: str,
    assets_dir: str,
    output_path: str,
    progress_cb: Callable | None = None,
    safe_mode: bool = False,
) -> dict[str, Any]:
    """ë©”ì¸ ë Œë”ë§ í•¨ìˆ˜"""

    # ì§„í–‰ë¥  ì½œë°± ê¸°ë³¸ê°’
    if progress_cb is None:
        progress_cb = lambda p, m: print(f"{p}%: {m}")

    try:
        # ë ˆì‹œí”¼ ë¡œë“œ
        progress_cb(5, "ë ˆì‹œí”¼ ë¡œë“œ ì¤‘...")
        with open(recipe_path, encoding="utf-8") as f:
            recipe = json.load(f)

        # ìì‚° ë¡œë“œ
        progress_cb(10, "ìì‚° ë¡œë“œ ì¤‘...")
        assets = load_assets_from_directory(assets_dir)

        # ìƒ· í´ë¦½ë“¤ ìƒì„±
        progress_cb(15, "ìƒ· í´ë¦½ ìƒì„± ì¤‘...")
        shots = recipe.get("shots", [])
        timeline = recipe.get("timeline", [])

        # timelineì´ ìˆìœ¼ë©´ timeline ì‚¬ìš©, ì—†ìœ¼ë©´ shots ì‚¬ìš©
        source_shots = timeline if timeline else shots
        max_shots = min(12, len(source_shots))  # MVP: ìµœëŒ€ 12ìƒ·
        shot_clips = []
        diagnostics = {"missing": set(), "resolved": 0, "built": 0, "reasons": []}

        # ì§„ë‹¨ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        from utils.diagnostics import heartbeat, loop_guard
        
        guard = loop_guard("render_shots", max_iter=max_shots * 2, warn_every=5)
        for i, shot in enumerate(source_shots[:max_shots]):
            heartbeat("render_shots")
            guard.tick({"shot_index": i, "max_shots": max_shots, "built_count": len(shot_clips)})
            
            progress_cb(15 + int(60 * i / max_shots), f"ìƒ· {i + 1}/{max_shots} ìƒì„± ì¤‘...")
            try:
                shot_clip = build_shot_clip(shot, assets, progress_cb, safe_mode)
                if shot_clip is not None:
                    shot_clips.append(shot_clip)
                    diagnostics["built"] += 1
                    print(
                        f"âœ… Shot {i + 1} created successfully (duration: {shot_clip.duration:.2f}s)"
                    )
                else:
                    diagnostics["reasons"].append(f"shot#{i} returned None")
                    print(f"âŒ Shot {i + 1} failed: returned None")
            except Exception as e:
                diagnostics["reasons"].append(f"shot#{i} error: {str(e)}")
                print(f"âŒ Shot {i + 1} error: {str(e)}")

        # ì§„ë‹¨ ì •ë³´ ì¶œë ¥
        print("\nğŸ” ë Œë”ë§ ì§„ë‹¨:")
        print(f"   - ì´ ìƒ·: {len(source_shots)}")
        print(f"   - ì²˜ë¦¬ëœ ìƒ·: {max_shots}")
        print(f"   - ì„±ê³µí•œ ìƒ·: {diagnostics['built']}")
        print(f"   - ì‹¤íŒ¨í•œ ìƒ·: {len(diagnostics['reasons'])}")
        if diagnostics["reasons"]:
            print(f"   - ì‹¤íŒ¨ ì›ì¸: {diagnostics['reasons'][:3]}...")  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ

        # ë¹ˆ ìƒ· ë°©ì–´
        if not shot_clips:
            msg = (
                "No usable shots were produced. "
                f"timeline={len(timeline)}, shots={len(shots)}, "
                f"resolved={diagnostics['resolved']}, built={diagnostics['built']}, "
                f"reasons={diagnostics['reasons']}"
            )
            raise ValueError(msg)

        # í´ë¦½ë“¤ í•©ì„±
        progress_cb(80, "í´ë¦½ í•©ì„± ì¤‘...")
        if len(shot_clips) == 1:
            final_clip = shot_clips[0]
        else:
            # ì „í™˜ íš¨ê³¼ ì ìš©
            final_clip = shot_clips[0]
            transition_guard = loop_guard("render_transitions", max_iter=len(shot_clips) * 2, warn_every=3)
            for i in range(1, len(shot_clips)):
                heartbeat("render_transitions")
                transition_guard.tick({"transition_index": i, "total_clips": len(shot_clips)})
                
                transition_type = "fade"  # ê¸°ë³¸ ì „í™˜
                final_clip = create_transition_effect(final_clip, shot_clips[i], transition_type)

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir = Path(output_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)

        # ê³ ê¸‰ ë¹„ë””ì˜¤ ì¸ì½”ë”© (ëª¨ë°”ì¼ ìµœì í™”)
        progress_cb(90, "ë¹„ë””ì˜¤ ì¸ì½”ë”© ì¤‘...")

        # Serene Minimal Gold ìŠ¤íƒ€ì¼ì´ë©´ ê³ í’ˆì§ˆ ì„¤ì •
        recipe_style = recipe.get("style", "")
        if recipe_style == "serene_minimal_gold":
            # ê³ í’ˆì§ˆ ëª¨ë°”ì¼ ìµœì í™” ì„¤ì •
            final_clip.write_videofile(
                output_path,
                fps=MOBILE_FPS,
                codec="libx264",
                audio=False,
                preset="slow",  # ê³ í’ˆì§ˆ í”„ë¦¬ì…‹
                bitrate="6M",  # ë†’ì€ ë¹„íŠ¸ë ˆì´íŠ¸
                ffmpeg_params=[
                    "-profile:v",
                    "high",
                    "-pix_fmt",
                    "yuv420p",
                    "-crf",
                    "18",  # ê³ í’ˆì§ˆ CRF
                    "-movflags",
                    "+faststart",
                    "-vf",
                    f"scale=1080:1920:force_original_aspect_ratio=decrease,pad=1080:1920:(ow-iw)/2:(oh-ih)/2:color={recipe.get('canvas', {}).get('bg_color', 'E9E3D9').replace('#', '')},format=yuv420p",
                ],
                threads=4,
                logger=None,
            )
        else:
            # ê¸°ë³¸ ì„¤ì •
            final_clip.write_videofile(
                output_path,
                fps=MOBILE_FPS,
                codec="libx264",
                audio=False,
                bitrate="4M",
                preset="medium",
                threads=4,
                logger=None,
            )
        final_clip.close()  # íŒŒì¼ ì ê¹€ ë°©ì§€

        # ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
        file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
        duration = final_clip.duration

        # ì‚¬ìš©ëœ ìì‚° ì •ë³´ ì €ì¥
        used_assets = {
            "video_file": output_path,
            "file_size_mb": round(file_size, 2),
            "duration_seconds": round(duration, 2),
            "resolution": f"{MOBILE_WIDTH}x{MOBILE_HEIGHT}",
            "fps": MOBILE_FPS,
            "used_assets": list(assets.keys()),
            "total_shots": len(shot_clips),
        }

        # used_assets.json ì €ì¥
        assets_info_path = output_dir / "used_assets.json"
        with open(assets_info_path, "w", encoding="utf-8") as f:
            json.dump(used_assets, f, ensure_ascii=False, indent=2)

        progress_cb(100, "ë Œë”ë§ ì™„ë£Œ!")

        return used_assets

    except Exception as e:
        progress_cb(0, f"ë Œë”ë§ ì‹¤íŒ¨: {str(e)}")
        raise e


def create_subtitle_srt(recipe: dict[str, Any], output_path: str) -> str:
    """ìë§‰ SRT íŒŒì¼ ìƒì„±"""

    srt_path = output_path.replace(".mp4", ".srt")
    srt_content = []

    shots = recipe.get("shots", [])
    for i, shot in enumerate(shots):
        start_time = shot.get("t0", 0)
        end_time = shot.get("t1", 0)

        # ì‹œê°„ í¬ë§· ë³€í™˜ (ì´ˆ -> SRT í¬ë§·)
        def seconds_to_srt_time(seconds):
            hours = int(seconds // 3600)
            minutes = int((seconds % 3600) // 60)
            secs = int(seconds % 60)
            millisecs = int((seconds % 1) * 1000)
            return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

        start_srt = seconds_to_srt_time(start_time)
        end_srt = seconds_to_srt_time(end_time)

        # í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        text_elements = shot.get("text", [])
        if text_elements:
            content = " ".join([elem.get("content", "") for elem in text_elements])
            if content.strip():
                srt_content.append(f"{i + 1}")
                srt_content.append(f"{start_srt} --> {end_srt}")
                srt_content.append(content.strip())
                srt_content.append("")

    # SRT íŒŒì¼ ì €ì¥
    if srt_content:
        with open(srt_path, "w", encoding="utf-8") as f:
            f.write("\n".join(srt_content))
        return srt_path

    return ""


def frame_variance(clip: VideoClip, t: float = 0.1) -> float:
    """íŠ¹ì • ì‹œì ì˜ í”„ë ˆì„ ë¶„ì‚° ê³„ì‚° (í‘/íšŒìƒ‰ í™”ë©´ ê°ì§€ìš©)"""
    try:
        frame = clip.get_frame(t)
        return float(np.var(frame))
    except Exception as e:
        print(f"í”„ë ˆì„ ë¶„ì‚° ê³„ì‚° ì‹¤íŒ¨: {e}")
        return 0.0


def render_single_shot_preview(
    shot: dict[str, Any], assets: dict[str, str], output_dir: str, safe_mode: bool = False
) -> dict[str, Any]:
    """ë‹¨ì¼ ìƒ· ë¯¸ë¦¬ë³´ê¸° ë Œë” (ë””ë²„ê·¸ìš©)"""
    try:
        # ë””ë²„ê·¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        debug_dir = Path(output_dir) / "debug"
        debug_dir.mkdir(parents=True, exist_ok=True)

        # ìƒ· í´ë¦½ ìƒì„± (2ì´ˆ ê³ ì •)
        shot_copy = shot.copy()
        if "t" in shot_copy:
            shot_copy["t"] = [0.0, 2.0]
        shot_copy["in"] = 0.0
        shot_copy["out"] = 2.0

        shot_clip = build_shot_clip(shot_copy, assets, safe_mode=safe_mode)

        if shot_clip is None:
            return {"error": "ìƒ· í´ë¦½ ìƒì„± ì‹¤íŒ¨"}

        # í”„ë ˆì„ ë¶„ì‚° ê³„ì‚°
        variance = frame_variance(shot_clip, t=0.1)

        # í”„ë ˆì„ ì´ë¯¸ì§€ ì €ì¥
        frame_path = debug_dir / "shot0_0100ms.png"
        shot_clip.save_frame(str(frame_path), t=0.1)

        # ë¯¸ë‹ˆ ë¹„ë””ì˜¤ ì €ì¥ (2ì´ˆ)
        video_path = debug_dir / "shot0_preview.mp4"
        shot_clip.write_videofile(
            str(video_path),
            fps=30,
            codec="libx264",
            audio=False,
            bitrate="2M",
            preset="fast",
            logger=None,
        )
        shot_clip.close()

        return {
            "variance": variance,
            "frame_path": str(frame_path),
            "video_path": str(video_path),
            "duration": shot_clip.duration,
            "warning": "í”„ë ˆì„ ë¶„ì‚°ì´ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤(í‘/íšŒìƒ‰ í™”ë©´ ì˜ì‹¬)" if variance < 10 else None,
        }

    except Exception as e:
        return {"error": f"ë¯¸ë¦¬ë³´ê¸° ìƒì„± ì‹¤íŒ¨: {str(e)}"}


def get_video_info(video_path: str) -> dict[str, Any]:
    """ë¹„ë””ì˜¤ íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""

    if not os.path.exists(video_path):
        return {}

    try:
        clip = VideoFileClip(video_path)
        info = {
            "file_size_mb": round(os.path.getsize(video_path) / (1024 * 1024), 2),
            "duration_seconds": round(clip.duration, 2),
            "fps": clip.fps,
            "size": clip.size,
            "resolution": f"{clip.w}x{clip.h}",
        }
        clip.close()
        return info
    except Exception as e:
        print(f"ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return {}
