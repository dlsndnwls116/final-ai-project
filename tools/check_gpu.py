#!/usr/bin/env python3
"""
GPU ì¸ì‹ ìµœì¢… ì ê²€ ìŠ¤í¬ë¦½íŠ¸
RTX 5070 + CUDA 12.8 + PyTorch í˜¸í™˜ì„± í™•ì¸
"""
import torch

print("=" * 50)
print("ğŸ® GPU ì¸ì‹ ìµœì¢… ì ê²€")
print("=" * 50)

print(f"torch = {torch.__version__}")
print(f"cuda available = {torch.cuda.is_available()}")
print(f"cuda version = {torch.version.cuda}")

if torch.cuda.is_available():
    device_name = torch.cuda.get_device_name(0)
    capability = torch.cuda.get_device_capability(0)
    
    print(f"device = {device_name}")
    print(f"capability = {capability}")
    
    # RTX 5070 íŠ¹í™” ì²´í¬
    if "RTX 5070" in device_name:
        print("âœ… RTX 5070 ê°ì§€ë¨")
    
    # SM 120 (Ada Lovelace Next) ì²´í¬
    if capability >= (12, 0):
        print("âœ… SM 120+ ì•„í‚¤í…ì²˜ ì§€ì›ë¨")
    else:
        print(f"âš ï¸ SM {capability[0]}.{capability[1]} (SM 120 ë¯¸ë§Œ)")
        
    # ë©”ëª¨ë¦¬ ì •ë³´
    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    print(f"VRAM = {total_memory:.1f}GB")
    
    # ê°„ë‹¨í•œ CUDA í…ŒìŠ¤íŠ¸
    try:
        x = torch.randn(100, 100).cuda()
        y = torch.mm(x, x.t())
        print("âœ… CUDA ì—°ì‚° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
    except Exception as e:
        print(f"âŒ CUDA ì—°ì‚° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
else:
    print("âŒ CUDA ì‚¬ìš© ë¶ˆê°€")

print("=" * 50)
